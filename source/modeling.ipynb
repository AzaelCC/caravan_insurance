{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6ec60b-23ac-4156-a754-cdf81389e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ccf67f-b139-4eda-b24d-dc9a795491d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aug_data():\n",
    "    names = np.array(['X' + str(i+1) for i in range(86)]) # Hace una lista de nombres de las variables que van desde X1 hasta X86\n",
    "    data = pd.read_csv('../data/ticdata2000.txt', delimiter = \"\\t\",header=None, names=names) # Le pone esos nombre en el header al data frame\n",
    "\n",
    "    X_train = data.iloc[:,0:85]  # Se seleccionan todas las variables a excepción de la variable respuesta que es la última\n",
    "    y_train = data.iloc[:, 85] # Se seleccion unicamente la variable respuesta\n",
    "\n",
    "    X_eval = pd.read_csv('../data/ticeval2000.txt', delimiter = \"\\t\",header=None, names=names[:-1])\n",
    "    y_eval = pd.read_csv('../data/tictgts2000.txt', delimiter = \"\\t\",header=None, names=['X86'])\n",
    "    \n",
    "    vars_to_change = [9,18,22,23,29,31,35,36]\n",
    "    new_vars = np.array(['X'+str(i+1)+'_2' for i in vars_to_change])\n",
    "    names = np.concatenate((names[:-1], new_vars))\n",
    "    class_reducer = {0:1, 1:1, 2:2, 3:2, 4:3, 5:3, 6:4, 7:4, 8:5, 9:5}\n",
    "\n",
    "    # Add new columns to X_train\n",
    "    X_train = pd.concat([X_train, X_train.iloc[:,vars_to_change]], axis=1) # Se copian las columnas que vamos a cambiar al final del dataframe\n",
    "    X_train.columns = names\n",
    "\n",
    "    # Reduce 10 classes to 5\n",
    "    for i in range(len(vars_to_change)):\n",
    "        X_train.iloc[:,i+85] = X_train.iloc[:,i+85].replace(class_reducer)\n",
    "\n",
    "    # Same for X_eval\n",
    "    X_eval = pd.concat([X_eval, X_eval.iloc[:,vars_to_change]], axis=1) # Copy columns to mutate\n",
    "    X_eval.columns = names\n",
    "\n",
    "    # Reduce 10 classes to 5\n",
    "    for i in range(len(vars_to_change)):\n",
    "        X_eval.iloc[:,i+85] = X_eval.iloc[:,i+85].replace(class_reducer)\n",
    "        \n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_eval = np.array(X_eval)\n",
    "    y_eval = np.array(y_eval)\n",
    "    \n",
    "    oh = OneHotEncoder(drop=[4], sparse=False, categories=[list(range(1,11))])\n",
    "    dummies_train = oh.fit_transform(X_train[:,4].reshape(-1, 1))\n",
    "    dummies_eval = oh.transform(X_eval[:,4].reshape(-1, 1))\n",
    "    X_train = np.concatenate((X_train, dummies_train), axis=1)\n",
    "    X_eval = np.concatenate((X_eval, dummies_eval), axis=1)\n",
    "    X_5_kept_cats = [1,2,3,5,6,7,8,9,10]\n",
    "    \n",
    "    names = np.concatenate((names, ['X5_2_' + str(i) for i in X_5_kept_cats]))\n",
    "\n",
    "    return X_train, y_train, X_eval, y_eval, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4a3224-9320-49b3-8162-b8bc215cd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_eval, y_eval, feature_names = load_aug_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f0459f-d534-4447-a7b5-323545c34118",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_num_vars = [43, 46, 53, 58, 60, 63]\n",
    "useful_zip_vars = [4, 17, 85, 86, 88, 89, 90, 91, 92]\n",
    "X_5 = list(range(93,102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64814a70-a0d6-4786-a804-f58ece8e984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets_of features to try\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))\n",
    "\n",
    "pre_feature_sets = list(powerset([useful_num_vars, useful_zip_vars, X_5]))\n",
    "feature_sets_names = list(powerset(['useful_num_vars', 'useful_zip_vars', 'X_5']))\n",
    "\n",
    "feature_sets = []\n",
    "for _set in pre_feature_sets:\n",
    "    compact_set = []\n",
    "    for l in _set:\n",
    "        compact_set += l\n",
    "    feature_sets.append(compact_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ad82d80-39af-4a6d-aa22-c1bdbae39791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33.,  1.,  3., ...,  1.,  0.,  0.],\n",
       "       [37.,  1.,  2., ...,  1.,  0.,  0.],\n",
       "       [37.,  1.,  2., ...,  1.,  0.,  0.],\n",
       "       ...,\n",
       "       [33.,  1.,  3., ...,  1.,  0.,  0.],\n",
       "       [34.,  1.,  3., ...,  1.,  0.,  0.],\n",
       "       [33.,  1.,  3., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_model(Model, model_vars, parameters={}, verbose=False):\n",
    "    X_train_subset, X_test_subset, X_eval_subset = prep_X_input(model_vars) # Subset parent datasets with the columns to use\n",
    "    # Model\n",
    "    mod = Model(**parameters).fit(X_train_subset, y_train)\n",
    "    \n",
    "    \n",
    "    # Predict and show test metrics\n",
    "    if (Model == LinearRegression):\n",
    "        probs_test = mod.predict(X_test_subset)\n",
    "        probs_eval = mod.predict(X_eval_subset)\n",
    "    else:\n",
    "        probs_test = mod.predict_proba(X_test_subset)[:,1]\n",
    "        probs_eval = mod.predict_proba(X_eval_subset)[:,1]\n",
    "    \n",
    "    print(\"Utilizando la de test\")\n",
    "    recall_test, svm_test = model_metrics(probs_test, y_test)\n",
    "    print(\"Utilizando la de evaluación\")\n",
    "    recall_eval, svm_eval = model_metrics(probs_eval, y_eval)\n",
    "    \n",
    "    return (recall_test, svm_test, recall_eval, svm_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
