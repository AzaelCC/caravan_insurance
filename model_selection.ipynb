{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Choosing a classification model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn.utils._testing import ignore_warnings\r\n",
    "from sklearn.exceptions import ConvergenceWarning\r\n",
    "\r\n",
    "# Local modules\r\n",
    "import utilities.utilities as pu\r\n",
    "\r\n",
    "# Logging\r\n",
    "import mlflow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "RANDOM_STATE = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Useful functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def cross_validate(X, y, model, params={}):\r\n",
    "    # Cross validate models\r\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\r\n",
    "    skf.get_n_splits(X, y)\r\n",
    "    cv_recalls = []\r\n",
    "    for train_index, test_index in skf.split(X, y):\r\n",
    "        X_train, X_test = X[train_index], X[test_index]\r\n",
    "        y_train, y_test = y[train_index], y[test_index]\r\n",
    "\r\n",
    "        ml = model(**params).fit(X_train, y_train)\r\n",
    "        y_probs = ml.predict_proba(X_test)[:,1]\r\n",
    "        recall = pu.model_metrics(y_probs, y_test)\r\n",
    "        \r\n",
    "        cv_recalls.append(recall)\r\n",
    "\r\n",
    "    mean_recall = np.mean(cv_recalls)\r\n",
    "    return mean_recall\r\n",
    "\r\n",
    "@ignore_warnings(category=ConvergenceWarning)\r\n",
    "def test_features(model, params={}):\r\n",
    "    # train and test with different feature_sets\r\n",
    "    recalls = []\r\n",
    "    best_recall = 0\r\n",
    "\r\n",
    "    for feature_set in range(len(feature_sets)):\r\n",
    "        # Subset data\r\n",
    "        X = data[:,feature_sets[feature_set]]\r\n",
    "        \r\n",
    "        # Cross validate models\r\n",
    "        mean_recall = cross_validate(X, y, model)\r\n",
    "\r\n",
    "        # Logging\r\n",
    "        with mlflow.start_run(run_name=str(model)):\r\n",
    "            mlflow.log_params(params)\r\n",
    "            mlflow.log_param('feature_id', feature_set)\r\n",
    "            mlflow.log_metric('mean_recall', mean_recall)\r\n",
    "        \r\n",
    "        recalls.append(mean_recall)\r\n",
    "\r\n",
    "        if mean_recall > best_recall:\r\n",
    "            best_recall = mean_recall\r\n",
    "            best_features = feature_set\r\n",
    "\r\n",
    "    try:\r\n",
    "        best_features # If not initilized, no good models found \r\n",
    "\r\n",
    "        X, X_eval= data[:,feature_sets[best_features]], data_eval[:,feature_sets[best_features]]\r\n",
    "        \r\n",
    "        ml = model(**params).fit(X, y)\r\n",
    "        y_probs = ml.predict_proba(X_eval)[:,1]\r\n",
    "        eval_recall = pu.model_metrics(y_probs, y_eval)\r\n",
    "\r\n",
    "        results = {'model': ml, \r\n",
    "                   'feature_set': best_features,\r\n",
    "                   'eval_recall': eval_recall,\r\n",
    "                   'cv_recalls': recalls}\r\n",
    "        return results\r\n",
    "    except:\r\n",
    "        print(\"No good models\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Load data\r\n",
    "data_path = os.path.realpath('./data')\r\n",
    "data, y, data_eval, y_eval, feature_names = pu.load_aug_data(data_path)\r\n",
    "feature_sets, feature_sets_names = pu.variable_sets()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from utilities.random_forest import RandomForestClassifier\r\n",
    "results_rf = test_features(RandomForestClassifier)\r\n",
    "results_rf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'model': RandomForestClassifier(),\n",
       " 'feature_set': 0,\n",
       " 'eval_recall': 0.4957983193277311,\n",
       " 'cv_recalls': [0.7586206896551725,\n",
       "  0.48850574712643674,\n",
       "  0.5833333333333333,\n",
       "  0.7068965517241379,\n",
       "  0.7270114942528735,\n",
       "  0.5057471264367815,\n",
       "  0.6925287356321839]}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LogisticRegression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "params={'solver':'newton-cg', \r\n",
    "        'max_iter':1000, \r\n",
    "        'random_state':0, \r\n",
    "        'fit_intercept':False, \r\n",
    "        'penalty':'l2'}\r\n",
    "\r\n",
    "results_lr = test_features(LogisticRegression, params)\r\n",
    "results_lr"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(fit_intercept=False, max_iter=1000, random_state=0,\n",
       "                    solver='newton-cg'),\n",
       " 'feature_set': 3,\n",
       " 'eval_recall': 0.4327731092436975,\n",
       " 'cv_recalls': [0.7442528735632185,\n",
       "  0.6005747126436781,\n",
       "  0.5804597701149425,\n",
       "  0.7471264367816092,\n",
       "  0.7471264367816092,\n",
       "  0.6293103448275862,\n",
       "  0.7385057471264368]}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "feature_sets_names[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('useful_num_vars',)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that random forest with default parameters and the '0' feature set (useful_num_vars) does better than the Logistic regression method"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e28bc482f088528914eca40f6f8b198eaf6cafd02d84c249df44e483a4f01484"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('article2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}